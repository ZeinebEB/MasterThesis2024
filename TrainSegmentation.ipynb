{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29fa8d0-db4a-4ea4-926a-3afec399a5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model.FFTRadNet import FFTRadNet\n",
    "from dataset.dataset import RADIal\n",
    "from dataset.encoder import ra_encoder\n",
    "from dataset.dataloader import CreateDataLoaders\n",
    "from model.Efficientnet_SEG import EfficientNetEnc_Seg\n",
    "\n",
    "import pkbar\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from loss import pixor_loss\n",
    "from utils.evaluation import run_evaluation\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='FFTRadNet Training')\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('-c', '--config', default='config/config_FFTRadNet_192_56-Seg.json',type=str,                            help='Path to the config file (default: config.json)')\n",
    "parser.add_argument('-r', '--resume', default=None, type=str,\n",
    "                            help='Path to the .pth model checkpoint to resume training')\n",
    "\n",
    "args = parser.parse_args()\n",
    "config = json.load(open(args.config))\n",
    "resume=args.resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f07990-0ef1-4318-a8cd-d521110d0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFTRadNet_RA_192_56___Jun-08-2024___21:19:45\n",
      "===========  Dataset  ==================:\n",
      "      Mode: sequence\n",
      "      Training: 6230\n",
      "      Validation: 986\n",
      "      Test: 1035\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "===========  Optimizer  ==================:\n",
      "      LR: 0.0001\n",
      "      step_size: 10\n",
      "      gamma: 0.9\n",
      "      num_epochs: 1\n",
      "\n",
      "Epoch: 1/1\n",
      "1558/1558 [====================] - 849s 545ms/step - loss: 65.9576 - freeSpace: 65.9576 - val_loss: 46365.8091 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 2/1\n",
      "1558/1558 [====================] - 848s 545ms/step - loss: 54.9496 - freeSpace: 54.9496 - val_loss: 43003.9105 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 3/1\n",
      "1558/1558 [====================] - 846s 543ms/step - loss: 48.0633 - freeSpace: 48.0633 - val_loss: 42600.5993 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 4/1\n",
      "1558/1558 [====================] - 834s 536ms/step - loss: 41.4555 - freeSpace: 41.4555 - val_loss: 46402.4447 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 5/1\n",
      "1558/1558 [====================] - 832s 534ms/step - loss: 36.0996 - freeSpace: 36.0996 - val_loss: 46169.7242 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 6/1\n",
      "1558/1558 [====================] - 836s 536ms/step - loss: 32.3213 - freeSpace: 32.3213 - val_loss: 47057.9306 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 7/1\n",
      "1558/1558 [====================] - 829s 532ms/step - loss: 29.3007 - freeSpace: 29.3007 - val_loss: 47498.1546 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 8/1\n",
      "1558/1558 [====================] - 825s 530ms/step - loss: 26.7383 - freeSpace: 26.7383 - val_loss: 47928.7223 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 9/1\n",
      "1558/1558 [====================] - 827s 531ms/step - loss: 24.7469 - freeSpace: 24.7469 - val_loss: 49269.9727 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 10/1\n",
      "1558/1558 [====================] - 828s 532ms/step - loss: 23.0587 - freeSpace: 23.0587 - val_loss: 52035.6962 - mIoU: 0.0000e+00\n",
      "\n",
      "Epoch: 11/1\n",
      "1558/1558 [====================] - 820s 527ms/step - loss: 21.1494 - freeSpace: 21.1494 - val_loss: 52341.9494 - mIoU: 0.6734\n",
      "\n",
      "Epoch: 12/1\n",
      "1558/1558 [====================] - 827s 531ms/step - loss: 19.6028 - freeSpace: 19.6028 - val_loss: 53973.9066 - mIoU: 0.6752\n",
      "\n",
      "Epoch: 13/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 18.4915 - freeSpace: 18.4915 - val_loss: 54302.5369 - mIoU: 0.6758\n",
      "\n",
      "Epoch: 14/1\n",
      "1558/1558 [====================] - 824s 529ms/step - loss: 17.6417 - freeSpace: 17.6417 - val_loss: 56737.6429 - mIoU: 0.6764\n",
      "\n",
      "Epoch: 15/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 16.7863 - freeSpace: 16.7863 - val_loss: 59217.4919 - mIoU: 0.6705\n",
      "\n",
      "Epoch: 16/1\n",
      "1558/1558 [====================] - 827s 531ms/step - loss: 16.0986 - freeSpace: 16.0986 - val_loss: 57942.8611 - mIoU: 0.6787\n",
      "\n",
      "Epoch: 17/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 15.3584 - freeSpace: 15.3584 - val_loss: 60086.6024 - mIoU: 0.6722\n",
      "\n",
      "Epoch: 18/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 14.9010 - freeSpace: 14.9010 - val_loss: 58582.2118 - mIoU: 0.6737\n",
      "\n",
      "Epoch: 19/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 14.3083 - freeSpace: 14.3083 - val_loss: 63110.3442 - mIoU: 0.6740\n",
      "\n",
      "Epoch: 20/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 13.7822 - freeSpace: 13.7822 - val_loss: 62279.6119 - mIoU: 0.6856\n",
      "\n",
      "Epoch: 21/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 13.1288 - freeSpace: 13.1288 - val_loss: 67776.6317 - mIoU: 0.6632\n",
      "\n",
      "Epoch: 22/1\n",
      "1558/1558 [====================] - 870s 559ms/step - loss: 12.3912 - freeSpace: 12.3912 - val_loss: 67235.2187 - mIoU: 0.6811\n",
      "\n",
      "Epoch: 23/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 12.1092 - freeSpace: 12.1092 - val_loss: 67964.5950 - mIoU: 0.6823\n",
      "\n",
      "Epoch: 24/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 11.8546 - freeSpace: 11.8546 - val_loss: 70432.4677 - mIoU: 0.6796\n",
      "\n",
      "Epoch: 25/1\n",
      "1558/1558 [====================] - 824s 529ms/step - loss: 11.5171 - freeSpace: 11.5171 - val_loss: 71494.0596 - mIoU: 0.6779\n",
      "\n",
      "Epoch: 26/1\n",
      "1558/1558 [====================] - 824s 529ms/step - loss: 11.2099 - freeSpace: 11.2099 - val_loss: 72708.4205 - mIoU: 0.6752\n",
      "\n",
      "Epoch: 27/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 10.9618 - freeSpace: 10.9618 - val_loss: 71402.1927 - mIoU: 0.6807\n",
      "\n",
      "Epoch: 28/1\n",
      "1558/1558 [====================] - 827s 531ms/step - loss: 10.7116 - freeSpace: 10.7116 - val_loss: 72087.8286 - mIoU: 0.6793\n",
      "\n",
      "Epoch: 29/1\n",
      "1558/1558 [====================] - 821s 527ms/step - loss: 10.4629 - freeSpace: 10.4629 - val_loss: 73395.0510 - mIoU: 0.6808\n",
      "\n",
      "Epoch: 30/1\n",
      "1558/1558 [====================] - 819s 525ms/step - loss: 10.2756 - freeSpace: 10.2756 - val_loss: 74287.7677 - mIoU: 0.6838\n",
      "\n",
      "Epoch: 31/1\n",
      "1558/1558 [====================] - 830s 533ms/step - loss: 9.9163 - freeSpace: 9.9163 - val_loss: 75709.5075 - mIoU: 0.6819\n",
      "\n",
      "Epoch: 32/1\n",
      "1558/1558 [====================] - 819s 526ms/step - loss: 9.5556 - freeSpace: 9.5556 - val_loss: 77508.5913 - mIoU: 0.6818\n",
      "\n",
      "Epoch: 33/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 9.3842 - freeSpace: 9.3842 - val_loss: 79275.4535 - mIoU: 0.6810\n",
      "\n",
      "Epoch: 34/1\n",
      "1558/1558 [====================] - 818s 525ms/step - loss: 9.2840 - freeSpace: 9.2840 - val_loss: 78194.5583 - mIoU: 0.6827\n",
      "\n",
      "Epoch: 35/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 9.0989 - freeSpace: 9.0989 - val_loss: 81121.8279 - mIoU: 0.6848\n",
      "\n",
      "Epoch: 36/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 8.9558 - freeSpace: 8.9558 - val_loss: 79580.6150 - mIoU: 0.6827\n",
      "\n",
      "Epoch: 37/1\n",
      "1558/1558 [====================] - 820s 526ms/step - loss: 8.8531 - freeSpace: 8.8531 - val_loss: 79220.1357 - mIoU: 0.6842\n",
      "\n",
      "Epoch: 38/1\n",
      "1558/1558 [====================] - 822s 528ms/step - loss: 8.7681 - freeSpace: 8.7681 - val_loss: 82448.9179 - mIoU: 0.6826\n",
      "\n",
      "Epoch: 39/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 8.6795 - freeSpace: 8.6795 - val_loss: 82545.1831 - mIoU: 0.6830\n",
      "\n",
      "Epoch: 40/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 8.4517 - freeSpace: 8.4517 - val_loss: 78892.7389 - mIoU: 0.6835\n",
      "\n",
      "Epoch: 41/1\n",
      "1558/1558 [====================] - 831s 533ms/step - loss: 8.2002 - freeSpace: 8.2002 - val_loss: 84621.9735 - mIoU: 0.6852\n",
      "\n",
      "Epoch: 42/1\n",
      "1558/1558 [====================] - 829s 532ms/step - loss: 7.9558 - freeSpace: 7.9558 - val_loss: 87252.4301 - mIoU: 0.6860\n",
      "\n",
      "Epoch: 43/1\n",
      "1558/1558 [====================] - 826s 530ms/step - loss: 7.9199 - freeSpace: 7.9199 - val_loss: 86829.8765 - mIoU: 0.6846\n",
      "\n",
      "Epoch: 44/1\n",
      "1558/1558 [====================] - 825s 530ms/step - loss: 7.8517 - freeSpace: 7.8517 - val_loss: 88720.1821 - mIoU: 0.6842\n",
      "\n",
      "Epoch: 45/1\n",
      "1558/1558 [====================] - 823s 529ms/step - loss: 7.7479 - freeSpace: 7.7479 - val_loss: 89261.4804 - mIoU: 0.6823\n",
      "\n",
      "Epoch: 46/1\n",
      "1558/1558 [====================] - 820s 526ms/step - loss: 7.6591 - freeSpace: 7.6591 - val_loss: 89142.8699 - mIoU: 0.6851\n",
      "\n",
      "Epoch: 47/1\n",
      " 765/1558 [========>...........] - ETA: 6:20 - loss: 7.6370 - freeSpace: 7.6370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 821s 527ms/step - loss: 7.4704 - freeSpace: 7.4704 - val_loss: 91633.7280 - mIoU: 0.6817\n",
      "\n",
      "Epoch: 49/1\n",
      "1558/1558 [====================] - 823s 528ms/step - loss: 7.4452 - freeSpace: 7.4452 - val_loss: 91686.9177 - mIoU: 0.6837\n",
      "\n",
      "Epoch: 50/1\n",
      "1558/1558 [====================] - 822s 528ms/step - loss: 7.3498 - freeSpace: 7.3498 - val_loss: 91145.2671 - mIoU: 0.6868\n",
      "\n",
      "Epoch: 51/1\n",
      " 443/1558 [====>...............] - ETA: 9:06 - loss: 7.1457 - freeSpace: 7.1457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 825s 530ms/step - loss: 6.9277 - freeSpace: 6.9277 - val_loss: 97458.1469 - mIoU: 0.6870\n",
      "\n",
      "Epoch: 55/1\n",
      "1558/1558 [====================] - 824s 529ms/step - loss: 6.8386 - freeSpace: 6.8386 - val_loss: 97446.7960 - mIoU: 0.6856\n",
      "\n",
      "Epoch: 56/1\n",
      " 890/1558 [==========>.........] - ETA: 5:19 - loss: 6.7743 - freeSpace: 6.7743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 823s 528ms/step - loss: 6.6926 - freeSpace: 6.6926 - val_loss: 99747.9640 - mIoU: 0.6867\n",
      "\n",
      "Epoch: 60/1\n",
      " 87/247 [======>.............] - ETA: 57s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 843s 541ms/step - loss: 6.2800 - freeSpace: 6.2800 - val_loss: 103638.7826 - mIoU: 0.6893\n",
      "\n",
      "Epoch: 64/1\n",
      "189/247 [==============>.....] - ETA: 24s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 823s 528ms/step - loss: 6.2068 - freeSpace: 6.2068 - val_loss: 104387.3608 - mIoU: 0.6875\n",
      "\n",
      "Epoch: 67/1\n",
      "1256/1558 [===============>....] - ETA: 2:22 - loss: 6.2085 - freeSpace: 6.2085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 821s 527ms/step - loss: 6.1397 - freeSpace: 6.1397 - val_loss: 106572.8527 - mIoU: 0.6870\n",
      "\n",
      "Epoch: 70/1\n",
      "1558/1558 [====================] - 821s 527ms/step - loss: 6.0769 - freeSpace: 6.0769 - val_loss: 104100.1143 - mIoU: 0.6842\n",
      "\n",
      "Epoch: 71/1\n",
      " 145/1558 [>...................] - ETA: 11:20 - loss: 6.0509 - freeSpace: 6.0509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 826s 530ms/step - loss: 5.9065 - freeSpace: 5.9065 - val_loss: 109652.6263 - mIoU: 0.6882\n",
      "\n",
      "Epoch: 73/1\n",
      "1558/1558 [====================] - 829s 532ms/step - loss: 5.8651 - freeSpace: 5.8651 - val_loss: 108984.0559 - mIoU: 0.6873\n",
      "\n",
      "Epoch: 74/1\n",
      "1085/1558 [============>.......] - ETA: 3:41 - loss: 5.8506 - freeSpace: 5.8506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 876s 562ms/step - loss: 5.7931 - freeSpace: 5.7931 - val_loss: 113920.2472 - mIoU: 0.6857\n",
      "\n",
      "Epoch: 77/1\n",
      "191/247 [==============>.....] - ETA: 19s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [====================] - 826s 530ms/step - loss: 5.7072 - freeSpace: 5.7072 - val_loss: 113016.4732 - mIoU: 0.6857\n",
      "\n",
      "Epoch: 81/1\n",
      "  64/1558 [....................] - ETA: 12:33 - loss: 5.6954 - freeSpace: 5.6954"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Setup random seed\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "torch.cuda.manual_seed(config['seed'])\n",
    "\n",
    "\n",
    "# create experience name\n",
    "curr_date = datetime.now()\n",
    "exp_name = config['name'] + '___' + curr_date.strftime('%b-%d-%Y___%H:%M:%S')\n",
    "print(exp_name)\n",
    "\n",
    "# Create directory structure\n",
    "output_folder = Path(\"Efficientnet_SEG_seq\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "(output_folder / exp_name).mkdir(parents=True, exist_ok=True)\n",
    "# and copy the config file\n",
    "with open(output_folder / exp_name / 'config.json', 'w') as outfile:\n",
    "    json.dump(config, outfile)\n",
    "\n",
    "# set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize tensorboard\n",
    "writer = SummaryWriter(output_folder / exp_name)\n",
    "\n",
    "# Load the dataset\n",
    "enc = ra_encoder(geometry = config['dataset']['geometry'], \n",
    "                    statistics = config['dataset']['statistics'],\n",
    "                    regression_layer = 2)\n",
    "\n",
    "dataset = RADIal(root_dir = config['dataset']['root_dir'],\n",
    "                    statistics= config['dataset']['statistics'],\n",
    "                    encoder=enc.encode,\n",
    "                    difficult=True)\n",
    "\n",
    "train_loader, val_loader, test_loader = CreateDataLoaders(dataset,config['dataloader'],config['seed'])\n",
    "\n",
    "\n",
    "# Create the model\n",
    "# net = FFTRadNet(blocks = config['model']['backbone_block'],\n",
    "#                     mimo_layer  = config['model']['MIMO_output'],\n",
    "#                     channels = config['model']['channels'], \n",
    "#                     regression_layer = 2, \n",
    "#                     detection_head = config['model']['DetectionHead'], \n",
    "#                     segmentation_head = config['model']['SegmentationHead'])\n",
    "net = EfficientNetEnc_Seg(n_channels=32, n_classes=1, segmentation_head=True)\n",
    "\n",
    "\n",
    "net.to('cuda')\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "lr = float(config['optimizer']['lr'])\n",
    "step_size = int(config['lr_scheduler']['step_size'])\n",
    "gamma = float(config['lr_scheduler']['gamma'])\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# num_epochs=int(config['num_epochs'])\n",
    "num_epochs=1\n",
    "\n",
    "\n",
    "print('===========  Optimizer  ==================:')\n",
    "print('      LR:', lr)\n",
    "print('      step_size:', step_size)\n",
    "print('      gamma:', gamma)\n",
    "print('      num_epochs:', num_epochs)\n",
    "print('')\n",
    "\n",
    "# Train\n",
    "startEpoch = 0\n",
    "global_step = 0\n",
    "history = {'train_loss':[],'val_loss':[],'lr':[],'mIoU':[]}\n",
    "best_mAP = 0\n",
    "\n",
    "freespace_loss = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "# resume=\"Segnet_SEG_seq/FFTRadNet_RA_192_56___May-24-2024___13:24:13/FFTRadNet_RA_192_56_epoch96_loss_157948.0619_IOU_0.6326.pth\"\n",
    "# if resume:\n",
    "#     print('===========  Resume training  ==================:')\n",
    "#     dict = torch.load(resume)\n",
    "#     net.load_state_dict(dict['net_state_dict'])\n",
    "#     optimizer.load_state_dict(dict['optimizer'])\n",
    "#     scheduler.load_state_dict(dict['scheduler'])\n",
    "#     startEpoch = dict['epoch']+1\n",
    "#     history = dict['history']\n",
    "#     global_step = dict['global_step']\n",
    "\n",
    "#     print('       ... Start at epoch:',startEpoch)\n",
    "\n",
    "\n",
    "for epoch in range(startEpoch,100):\n",
    "\n",
    "    kbar = pkbar.Kbar(target=len(train_loader), epoch=epoch, num_epochs=num_epochs, width=20, always_stateful=False)\n",
    "\n",
    "    ###################http://10.9.238.92:8080/\n",
    "    ## Training loop ##\n",
    "    ###################\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs = data[0].to('cuda').float()\n",
    "        if(config['model']['SegmentationHead']=='True'):\n",
    "            seg_map_label = data[2].to('cuda').double()\n",
    "\n",
    "        # reset the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass, enable to track our gradient\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = net(inputs)\n",
    "\n",
    "\n",
    "\n",
    "        prediction = outputs['Segmentation'].contiguous().flatten()\n",
    "        label = seg_map_label.contiguous().flatten()        \n",
    "        loss_seg = freespace_loss(prediction, label)\n",
    "        loss_seg *= inputs.size(0)\n",
    "\n",
    "        loss_seg *=config['losses']['weight'][2]\n",
    "\n",
    "\n",
    "        loss =  loss_seg\n",
    "\n",
    "        writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "        writer.add_scalar('Loss/train_freespace', loss_seg.item(), global_step)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        kbar.update(i, values=[(\"loss\", loss.item()),(\"freeSpace\", loss_seg.item())])\n",
    "\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(running_loss / len(train_loader.dataset))\n",
    "    history['lr'].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "\n",
    "    ######################\n",
    "    ## validation phase ##\n",
    "    ######################\n",
    "\n",
    "    eval = run_evaluation(net,val_loader,enc,check_perf=(epoch>=10),\n",
    "                            detection_loss=None,segmentation_loss=freespace_loss,\n",
    "                            losses_params=config['losses'])\n",
    "\n",
    "    history['val_loss'].append(eval['loss'])\n",
    "\n",
    "    history['mIoU'].append(eval['mIoU'])\n",
    "\n",
    "    kbar.add(1, values=[(\"val_loss\", eval['loss']),(\"mIoU\", eval['mIoU'])])\n",
    "\n",
    "\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "    writer.add_scalar('Loss/test', eval['loss'], global_step)\n",
    "    writer.add_scalar('Metrics/mIoU', eval['mIoU'], global_step)\n",
    "\n",
    "    # Saving all checkpoint as the best checkpoint for multi-task is a balance between both --> up to the user to decide\n",
    "    name_output_file = config['name']+'_epoch{:02d}_loss_{:.4f}_IOU_{:.4f}.pth'.format(epoch, eval['loss'],eval['mIoU'])\n",
    "    filename = output_folder / exp_name / name_output_file\n",
    "\n",
    "    checkpoint={}\n",
    "    checkpoint['net_state_dict'] = net.state_dict()\n",
    "    checkpoint['optimizer'] = optimizer.state_dict()\n",
    "    checkpoint['scheduler'] = scheduler.state_dict()\n",
    "    checkpoint['epoch'] = epoch\n",
    "    checkpoint['history'] = history\n",
    "    checkpoint['global_step'] = global_step\n",
    "\n",
    "    torch.save(checkpoint,filename)\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc28af-ed9a-46cd-b57d-2c8ee1730b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('===========  Resume training  ==================:')\n",
    "# dict = torch.load(\"../output_training-Seg/FFTRadNet_RA_192_56___Jan-31-2024___21:56:34/FFTRadNet_RA_192_56_epoch78_loss_94434.5930_IOU_0.6623.pth\")\n",
    "# net.load_state_dict(dict['net_state_dict'])\n",
    "# optimizer.load_state_dict(dict['optimizer'])\n",
    "# scheduler.load_state_dict(dict['scheduler'])\n",
    "# startEpoch = dict['epoch']+1\n",
    "# history = dict['history']\n",
    "# global_step = dict['global_step']\n",
    "\n",
    "# print('       ... Start at epoch:',startEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d097fb-6cae-4f2f-a716-61292f334642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
